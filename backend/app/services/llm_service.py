# FILE: backend/app/services/llm_service.py
# PHOENIX PROTOCOL - INGESTION INTELLIGENCE V5.3 (KOSOVO CONTEXT HARDENING)
# 1. SAFETY: Reinforced "Kosovo Jurisdiction" in all system prompts to prevent dialect/legal drift.
# 2. CONSISTENCY: Enforced standard Albanian language output for all analysis tasks.
# 3. LOGIC: Preserved the "Debate Judge" logic which is performing well.

import os
import json
import logging
import httpx
import re
from typing import List, Dict, Any, Optional
from openai import OpenAI 
from groq import Groq

logger = logging.getLogger(__name__)

# --- CONFIGURATION ---
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
OPENROUTER_MODEL = "deepseek/deepseek-chat"

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_MODEL_NAME = "llama-3.3-70b-versatile" 

OLLAMA_URL = os.environ.get("LOCAL_LLM_URL", "http://local-llm:11434/api/generate")
LOCAL_MODEL_NAME = "llama3"

# --- CLIENT INITIALIZATION ---
_deepseek_client: Optional[OpenAI] = None
_groq_client: Optional[Groq] = None

def get_deepseek_client() -> Optional[OpenAI]:
    global _deepseek_client
    if _deepseek_client: return _deepseek_client
    if DEEPSEEK_API_KEY:
        try:
            _deepseek_client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=OPENROUTER_BASE_URL)
            return _deepseek_client
        except Exception as e:
            logger.error(f"DeepSeek Init Failed: {e}")
    return None

def get_groq_client() -> Optional[Groq]:
    global _groq_client
    if _groq_client: return _groq_client
    if GROQ_API_KEY:
        try:
            _groq_client = Groq(api_key=GROQ_API_KEY)
            return _groq_client
        except Exception as e:
            logger.error(f"Groq Init Failed: {e}")
    return None

# --- HELPER: ROBUST JSON PARSER ---
def _parse_json_safely(content: str) -> Dict[str, Any]:
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
        if match:
            try: return json.loads(match.group(1))
            except: pass
        start, end = content.find('{'), content.rfind('}')
        if start != -1 and end != -1:
            try: return json.loads(content[start:end+1])
            except: pass
        return {}

# --- EXECUTION ENGINES ---

def _call_deepseek(system_prompt: str, user_prompt: str, json_mode: bool = False) -> Optional[str]:
    client = get_deepseek_client()
    if not client: return None
    try:
        kwargs = {
            "model": OPENROUTER_MODEL,
            "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            "temperature": 0.1, 
            "extra_headers": {"HTTP-Referer": "https://juristi.tech", "X-Title": "Juristi AI Analysis"}
        }
        if json_mode: kwargs["response_format"] = {"type": "json_object"}
        response = client.chat.completions.create(**kwargs)
        return response.choices[0].message.content
    except Exception as e:
        logger.warning(f"âš ï¸ DeepSeek Call Failed: {e}")
        return None

def _call_groq(system_prompt: str, user_prompt: str, json_mode: bool = False) -> Optional[str]:
    client = get_groq_client()
    if not client: return None
    try:
        kwargs = {
            "model": GROQ_MODEL_NAME,
            "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            "temperature": 0.1,
        }
        if json_mode: kwargs["response_format"] = {"type": "json_object"}
        response = client.chat.completions.create(**kwargs)
        return response.choices[0].message.content
    except Exception as e:
        logger.warning(f"âš ï¸ Groq Call Failed: {e}")
        return None

def _call_local_llm(prompt: str, json_mode: bool = False) -> str:
    logger.info(f"ğŸ”„ Switching to LOCAL LLM ({LOCAL_MODEL_NAME})...")
    try:
        payload = {
            "model": LOCAL_MODEL_NAME,
            "prompt": prompt,
            "stream": False,
            "options": {"temperature": 0.1, "num_ctx": 4096},
            "format": "json" if json_mode else None
        }
        with httpx.Client(timeout=60.0) as client:
            response = client.post(OLLAMA_URL, json=payload)
            return response.json().get("response", "")
    except Exception:
        return ""

# --- UNIVERSAL EVIDENCE ENGINE (V5.3) ---

def generate_summary(text: str) -> str:
    truncated_text = text[:20000] 
    system_prompt = (
        "Ti je Analist GjyqÃ«sor pÃ«r RepublikÃ«n e KosovÃ«s. "
        "Detyra jote Ã«shtÃ« tÃ« krijosh njÃ« pÃ«rmbledhje tÃ« qartÃ« dhe koncize tÃ« dokumentit. "
        "RREGULL: PÃ«rdor gjuhÃ« standarde shqipe (dialekti i KosovÃ«s ku aplikohet terminologjia ligjore). "
        "Fokuso te: "
        "1. KUSH janÃ« palÃ«t? "
        "2. CILI Ã«shtÃ« konflikti thelbÃ«sor? "
        "3. KUR ka ndodhur ngjarja? "
        "4. STATUSI aktual procedural?"
    )
    user_prompt = f"DOKUMENTI:\n{truncated_text}"
    
    res = _call_deepseek(system_prompt, user_prompt)
    if res: return res
    res = _call_groq(system_prompt, user_prompt)
    if res: return res
    return _call_local_llm(f"{system_prompt}\n\n{user_prompt}") or "PÃ«rmbledhja e padisponueshme."

def extract_findings_from_text(text: str) -> List[Dict[str, Any]]:
    """
    Extracts universal legal building blocks from text.
    """
    truncated_text = text[:25000]
    
    # PHOENIX V5.3 UPGRADE: Added explicit "Kosovo Legal Context" instruction
    system_prompt = """
    Ti je Motor i Nxjerrjes sÃ« Provave pÃ«r Sistemin e DrejtÃ«sisÃ« nÃ« KosovÃ«.
    
    DETYRA: Identifiko elementet kyÃ§e ligjore.
    
    KATEGORITÃ‹ E PROVAVE:
    - EVENT (Ngjarje)
    - EVIDENCE (ProvÃ« materiale/dokumentare)
    - CLAIM (Pretendim i njÃ« pale)
    - CONTRADICTION (MospÃ«rputhje mes palÃ«ve)
    - QUANTITY (Shuma parash, sipÃ«rfaqe toke)
    - DEADLINE (Afate ligjore/procedurale)
    
    DETYRIM: PÃ«rgjigju vetÃ«m nÃ« JSON valid. TÃ« paktÃ«n 5 gjetje nÃ«se ekzistojnÃ«.
    
    SHEMBUJ TÃ‹ KUALITETIT TÃ‹ LARTÃ‹ (KOSOVÃ‹):
    - PÃ«r "CLAIM": {"finding_text": "PaditÃ«si kÃ«rkon kompensim dÃ«mi.", "category": "CLAIM"}
    - PÃ«r "DEADLINE": {"finding_text": "Afati pÃ«r ankesÃ« Ã«shtÃ« 15 ditÃ« sipas Ligjit pÃ«r ProcedurÃ«n Kontestimore.", "category": "DEADLINE"}

    FORMATI JSON:
    {
      "findings": [
        {
          "finding_text": "...",
          "source_text": "...",
          "category": "..."
        }
      ]
    }
    """
    user_prompt = f"DOSJA:\n{truncated_text}"

    content = _call_deepseek(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content).get("findings", [])
    
    content = _call_groq(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content).get("findings", [])
    
    content = _call_local_llm(f"{system_prompt}\n\n{user_prompt}", json_mode=True)
    if content: return _parse_json_safely(content).get("findings", [])
    
    return []

def extract_graph_data(text: str) -> Dict[str, List[Dict]]:
    truncated_text = text[:15000]
    system_prompt = """
    Ti je Inxhinier i Grafit Ligjor pÃ«r Rastet e KosovÃ«s.
    Detyra: Krijo hartÃ«n e marrÃ«dhÃ«nieve mes entiteteve (PalÃ«, GjykatÃ«s, Provave).
    MARRÃ‹DHÃ‹NIET: ACCUSES, OWES, CLAIMS, WITNESSED, OCCURRED_ON, CONTRADICTS.
    FORMATI JSON: {"entities": [], "relations": []}
    """
    user_prompt = f"TEKSTI:\n{truncated_text}"
    content = _call_deepseek(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content)
    content = _call_groq(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content)
    return {"entities": [], "relations": []}

def analyze_case_contradictions(text: str) -> Dict[str, Any]:
    """
    High-Level Strategy Analysis (Debate Judge).
    """
    truncated_text = text[:25000]
    
    system_prompt = """
    Ti je Gjyqtar i Debatit Ligjor nÃ« GjykatÃ«n e PrishtinÃ«s.
    DETYRA: Analizo pÃ«rplasjen ligjore nÃ« kÃ«tÃ« dosje.
    
    PROCESI KOGNITIV:
    1. Identifiko PaditÃ«sin dhe pretendimin kryesor.
    2. Identifiko tÃ« Paditurin dhe mbrojtjen kryesore.
    3. Gjej kontradiktat direkte (Ku nuk pajtohen?).
    4. Gjej provat mbÃ«shtetÃ«se pÃ«r secilin.
    5. Ã‡farÃ« mungon pÃ«r tÃ« marrÃ« vendim?
    
    OUTPUT JSON:
    {
        "summary_analysis": "PÃ«rmbledhje strategjike e rastit.",
        "conflicting_parties": [
            {"party_name": "PaditÃ«si", "core_claim": "..."},
            {"party_name": "I Padituri", "core_claim": "..."}
        ],
        "contradictions": ["..."],
        "key_evidence": ["..."],
        "missing_info": ["..."]
    }
    """
    user_prompt = f"DOSJA:\n{truncated_text}"

    content = _call_deepseek(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content)
    
    content = _call_groq(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content)

    return {}

def generate_socratic_response(socratic_context: List[Dict], question: str) -> Dict:
    return {"answer": "Logic moved to R-A-G Service.", "sources": []}

def extract_deadlines_from_text(text: str) -> List[Dict[str, Any]]:
    return []