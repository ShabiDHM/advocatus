# FILE: backend/app/services/llm_service.py
# PHOENIX PROTOCOL - INGESTION INTELLIGENCE V3
# 1. UPGRADE: 'extract_graph_data' now hunts for Conflict & Money (Litigation Graph).
# 2. UPGRADE: 'extract_findings_from_text' performs Forensic auditing on Dates & Amounts.
# 3. GOAL: Feed high-quality data to the Chatbot & Graph.

import os
import json
import logging
import httpx
import re
from typing import List, Dict, Any, Optional
from openai import OpenAI 
from groq import Groq

logger = logging.getLogger(__name__)

# --- CONFIGURATION ---
DEEPSEEK_API_KEY = os.getenv("DEEPSEEK_API_KEY")
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
OPENROUTER_MODEL = "deepseek/deepseek-chat"

GROQ_API_KEY = os.getenv("GROQ_API_KEY")
GROQ_MODEL_NAME = "llama-3.3-70b-versatile" 

OLLAMA_URL = os.environ.get("LOCAL_LLM_URL", "http://local-llm:11434/api/generate")
LOCAL_MODEL_NAME = "llama3"

# --- CLIENT INITIALIZATION ---
_deepseek_client: Optional[OpenAI] = None
_groq_client: Optional[Groq] = None

def get_deepseek_client() -> Optional[OpenAI]:
    global _deepseek_client
    if _deepseek_client: return _deepseek_client
    if DEEPSEEK_API_KEY:
        try:
            _deepseek_client = OpenAI(api_key=DEEPSEEK_API_KEY, base_url=OPENROUTER_BASE_URL)
            return _deepseek_client
        except Exception as e:
            logger.error(f"DeepSeek Init Failed: {e}")
    return None

def get_groq_client() -> Optional[Groq]:
    global _groq_client
    if _groq_client: return _groq_client
    if GROQ_API_KEY:
        try:
            _groq_client = Groq(api_key=GROQ_API_KEY)
            return _groq_client
        except Exception as e:
            logger.error(f"Groq Init Failed: {e}")
    return None

# --- HELPER: ROBUST JSON PARSER ---
def _parse_json_safely(content: str) -> Dict[str, Any]:
    try:
        return json.loads(content)
    except json.JSONDecodeError:
        match = re.search(r'```(?:json)?\s*(\{.*?\})\s*```', content, re.DOTALL)
        if match:
            try: return json.loads(match.group(1))
            except: pass
        start, end = content.find('{'), content.rfind('}')
        if start != -1 and end != -1:
            try: return json.loads(content[start:end+1])
            except: pass
        return {}

# --- EXECUTION ENGINES ---

def _call_deepseek(system_prompt: str, user_prompt: str, json_mode: bool = False) -> Optional[str]:
    client = get_deepseek_client()
    if not client: return None
    try:
        kwargs = {
            "model": OPENROUTER_MODEL,
            "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            "temperature": 0.1,
            "extra_headers": {"HTTP-Referer": "https://juristi.tech", "X-Title": "Juristi AI"}
        }
        if json_mode: kwargs["response_format"] = {"type": "json_object"}
        response = client.chat.completions.create(**kwargs)
        return response.choices[0].message.content
    except Exception as e:
        logger.warning(f"âš ï¸ DeepSeek Call Failed: {e}")
        return None

def _call_groq(system_prompt: str, user_prompt: str, json_mode: bool = False) -> Optional[str]:
    client = get_groq_client()
    if not client: return None
    try:
        kwargs = {
            "model": GROQ_MODEL_NAME,
            "messages": [{"role": "system", "content": system_prompt}, {"role": "user", "content": user_prompt}],
            "temperature": 0.1,
        }
        if json_mode: kwargs["response_format"] = {"type": "json_object"}
        response = client.chat.completions.create(**kwargs)
        return response.choices[0].message.content
    except Exception as e:
        logger.warning(f"âš ï¸ Groq Call Failed: {e}")
        return None

def _call_local_llm(prompt: str, json_mode: bool = False) -> str:
    logger.info(f"ðŸ”„ Switching to LOCAL LLM ({LOCAL_MODEL_NAME})...")
    try:
        payload = {
            "model": LOCAL_MODEL_NAME,
            "prompt": prompt,
            "stream": False,
            "options": {"temperature": 0.1, "num_ctx": 4096},
            "format": "json" if json_mode else None
        }
        with httpx.Client(timeout=60.0) as client:
            response = client.post(OLLAMA_URL, json=payload)
            return response.json().get("response", "")
    except Exception:
        return ""

# --- CORE SERVICES (UPGRADED) ---

def generate_summary(text: str) -> str:
    truncated_text = text[:20000] # Increased context window
    system_prompt = (
        "Ti je 'Juristi AI', njÃ« asistent ligjor elitar. "
        "Detyra: Krijo njÃ« pÃ«rmbledhje ekzekutive tÃ« kÃ«tij dokumenti nÃ« gjuhÃ«n Shqipe. "
        "Fokusi: Identifiko PalÃ«t, Objektin e MarrÃ«veshjes/Konfliktit, dhe Datat Kryesore. "
        "Stili: Profesional, konciz, dhe i qartÃ«."
    )
    user_prompt = f"DOKUMENTI:\n{truncated_text}"
    
    res = _call_deepseek(system_prompt, user_prompt)
    if res: return res
    res = _call_groq(system_prompt, user_prompt)
    if res: return res
    return _call_local_llm(f"{system_prompt}\n\n{user_prompt}") or "PÃ«rmbledhja e padisponueshme."

def extract_findings_from_text(text: str) -> List[Dict[str, Any]]:
    """
    Forensic Extraction: Hunts for Dates, Money, Obligations, and Anomalies.
    """
    truncated_text = text[:20000]
    
    system_prompt = """
    Ti je Auditor Ligjor Forenzik. Analizo tekstin pÃ«r Gjetje Kritike (Facts).
    
    KATEGORITÃ‹ E KÃ‹RKIMIT:
    1. ðŸ“… AFATET & KRONOLOGJIA: Identifiko Ã§do datÃ«. A ka data qÃ« bien ndesh (psh. afati para nÃ«nshkrimit)? ShÃ«noji si rreziqe.
    2. ðŸ’° DETYRIMET FINANCIARE: Shuma, KÃ«ste, Penalitete, Afate pagese.
    3. âš–ï¸ DETYRIMET LIGJORE: Ã‡farÃ« duhet tÃ« bÃ«jÃ« secila palÃ«? (DorÃ«zimi i Ã§elÃ«save, Raportet, etj).
    
    FORMATI JSON (STRIKT):
    {
      "findings": [
        {
          "finding_text": "PÃ«rshkrimi i qartÃ« i faktit (psh. 'Ã‡elÃ«sat duhet tÃ« dorÃ«zohen mÃ« 1 Dhjetor 2025')",
          "source_text": "Cito tekstin origjinal nga dokumenti pÃ«r saktÃ«si",
          "category": "DATE" | "MONEY" | "OBLIGATION" | "RISK"
        }
      ]
    }
    """
    user_prompt = f"TEKSTI PÃ‹R ANALIZÃ‹:\n{truncated_text}"

    # Try DeepSeek first (Best logic)
    content = _call_deepseek(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content).get("findings", [])
    
    # Fallback to Groq
    content = _call_groq(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content).get("findings", [])
    
    # Fallback to Local
    content = _call_local_llm(f"{system_prompt}\n\n{user_prompt}", json_mode=True)
    if content: return _parse_json_safely(content).get("findings", [])
    
    return []

def extract_graph_data(text: str) -> Dict[str, List[Dict]]:
    """
    Litigation Graph Extraction: Builds the 'Conflict Map'.
    """
    truncated_text = text[:15000]
    
    system_prompt = """
    Ti je Inxhinier i Grafit Ligjor. Detyra jote Ã«shtÃ« tÃ« nxjerrÃ«sh Entitetet dhe MarrÃ«dhÃ«niet pÃ«r njÃ« bazÃ« tÃ« dhÃ«nash Neo4j.
    
    ENTITETET (Nodes):
    - Person (Emra njerÃ«zish)
    - Organization (Kompania, Institucione)
    - Money (Shuma specifike psh. '2500 EUR')
    - Date (Data specifike)
    - Claim (Pretendime, psh. 'Mospagim qiraje', 'Shkelje afati')
    
    MARRÃ‹DHÃ‹NIET (Edges - Subject -> Relation -> Object):
    - Transaksione: PAID, OWES, AGREED_TO_PAY
    - Ligjore: SIGNED, REPRESENTS, SUED
    - Konflikt: ACCUSES, CONTRADICTS, VIOLATED
    - Kohore: DUE_ON, SIGNED_ON
    
    SHEMBULL LOGJIK:
    NÃ«se teksti thotÃ« "Artani akuzon Besnikun pÃ«r vonesÃ«", krijo:
    Person(Artan) --ACCUSES--> Person(Besnik)
    
    FORMATI JSON (STRIKT):
    {
      "entities": [{"name": "Emri", "type": "Person | Organization | Money | Date | Claim"}],
      "relations": [{"subject": "Emri1", "relation": "UPPERCASE_VERB", "object": "Emri2"}]
    }
    """
    user_prompt = f"TEKSTI:\n{truncated_text}"
    
    content = _call_deepseek(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content)
    
    content = _call_groq(system_prompt, user_prompt, json_mode=True)
    if content: return _parse_json_safely(content)
    
    return {"entities": [], "relations": []}

def generate_socratic_response(socratic_context: List[Dict], question: str) -> Dict:
    return {"answer": "Logic moved to RAG Service.", "sources": []}

def extract_deadlines_from_text(text: str) -> List[Dict[str, Any]]:
    # Can be expanded later for specific calendar events
    return []