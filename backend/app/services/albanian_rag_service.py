# FILE: backend/app/services/albanian_rag_service.py
# PHOENIX PROTOCOL - AGGRESSIVE LAWYER MODE
# 1. LOGIC CHECK: Forces AI to scan for Date/Time anomalies (Chronology).
# 2. LEGAL AUDIT: Forces AI to cite specific articles from the Knowledge Base instead of generic statements.
# 3. GOAL: Catch the "Dec 15 vs Dec 1" error and cite the LMD.

import os
import asyncio
import logging
from typing import AsyncGenerator, List, Optional, Dict, Protocol, cast, Any
from openai import AsyncOpenAI

from .graph_service import graph_service

logger = logging.getLogger(__name__)

# --- CONFIGURATION ---
DEEPSEEK_API_KEY = os.environ.get("DEEPSEEK_API_KEY") 
OPENROUTER_BASE_URL = "https://openrouter.ai/api/v1"
OPENROUTER_MODEL = "deepseek/deepseek-chat" 
LOCAL_LLM_URL = os.environ.get("LOCAL_LLM_URL", "http://local-llm:11434/api/chat")
LOCAL_MODEL_NAME = "llama3"

# --- PROTOCOLS ---
class VectorStoreServiceProtocol(Protocol):
    def query_by_vector(self, embedding: List[float], case_id: str, n_results: int, document_ids: Optional[List[str]]) -> List[Dict]: ...
    def query_legal_knowledge_base(self, embedding: List[float], n_results: int, jurisdiction: str) -> List[Dict]: ...

class LanguageDetectorProtocol(Protocol):
    def detect_language(self, text: str) -> bool: ...

class AlbanianRAGService:
    def __init__(
        self,
        vector_store: VectorStoreServiceProtocol,
        llm_client: Any,
        language_detector: LanguageDetectorProtocol
    ):
        self.vector_store = cast(VectorStoreServiceProtocol, vector_store)
        self.language_detector = language_detector
        
        if DEEPSEEK_API_KEY:
            self.client = AsyncOpenAI(api_key=DEEPSEEK_API_KEY, base_url=OPENROUTER_BASE_URL)
        else:
            self.client = None

    async def chat(
        self, 
        query: str, 
        case_id: str, 
        document_ids: Optional[List[str]] = None, 
        jurisdiction: str = 'ks'
    ) -> str:
        full_response_parts = []
        async for chunk in self.chat_stream(query, case_id, document_ids, jurisdiction):
            if chunk: full_response_parts.append(chunk)
        return "".join(full_response_parts)

    async def _rerank_chunks(self, query: str, chunks: List[Dict]) -> List[Dict]:
        if not chunks: return []
        unique_texts = {c.get('text', ''): c for c in chunks}
        return list(unique_texts.values())

    async def _call_local_backup(self, system_prompt: str, user_prompt: str) -> str:
        return "ShÃ«rbimi AI momentalisht i padisponueshÃ«m."

    async def chat_stream(
        self, 
        query: str, 
        case_id: str, 
        document_ids: Optional[List[str]] = None, 
        jurisdiction: str = 'ks'
    ) -> AsyncGenerator[str, None]:
        
        user_docs, kb_docs, graph_knowledge = [], [], []
        
        try:
            from .embedding_service import generate_embedding
            query_embedding = await asyncio.to_thread(generate_embedding, query, 'standard')
            
            if query_embedding:
                results = await asyncio.gather(
                    asyncio.to_thread(self.vector_store.query_by_vector, embedding=query_embedding, case_id=case_id, n_results=10, document_ids=document_ids),
                    # PHOENIX: Increased KB results to 6 to ensure we get the specific articles
                    asyncio.to_thread(self.vector_store.query_legal_knowledge_base, embedding=query_embedding, n_results=6, jurisdiction=jurisdiction),
                    asyncio.to_thread(graph_service.find_contradictions, case_id),
                    return_exceptions=True
                )
                user_docs = results[0] if isinstance(results[0], list) else []
                kb_docs = results[1] if isinstance(results[1], list) else []
                graph_knowledge = results[2] if isinstance(results[2], str) and "No direct" not in results[2] else ""
        except Exception as e:
            logger.error(f"Retrieval Phase Error: {e}")

        context_text = ""
        if user_docs:
            reranked_user_docs = await self._rerank_chunks(query, user_docs)
            context_text += "### FAKTE NGA DOSJA (EVIDENCA):\n"
            for chunk in reranked_user_docs[:6]:
                context_text += f"DOKUMENTI '{chunk.get('document_name', 'Unknown')}':\n{chunk.get('text', '')}\n---\n"
        
        if graph_knowledge:
            context_text += f"\n### FLAMUJ TÃ‹ KUQ NGA GRAFI:\n{graph_knowledge}\n---\n"
        
        if kb_docs:
            context_text += "\n### BAZA LIGJORE (LIGJET E APLIKUESHME):\n"
            for chunk in kb_docs[:4]: # Use more laws
                context_text += f"BURIMI '{chunk.get('document_name', 'Ligj')}':\n{chunk.get('text', '')}\n---\n"
        
        if not context_text:
            context_text = "Nuk u gjetÃ«n dokumente ose informacione relevante."

        jurisdiction_name = "RepublikÃ«s sÃ« ShqipÃ«risÃ«" if jurisdiction == 'al' else "RepublikÃ«s sÃ« KosovÃ«s"
        
        # PHOENIX: Aggressive Lawyer Prompt
        system_prompt = f"""
        Ti je "Juristi AI", Avokat Senior Forenzik nÃ« {jurisdiction_name}.
        
        DETYRA JOTE:
        BÃ«j njÃ« "Cross-Examination" (KundÃ«r-Pyetje) tÃ« fakteve tÃ« dosjes kundrejt (A) LogjikÃ«s dhe (B) Ligjit.

        STRUKTURA E PÃ‹RGJIGJES (Markdown):

        ### 1. PÃ«rmbledhje Ekzekutive
        PÃ«rgjigje direkte. NÃ«se dokumenti ka gabime logjike (data, shuma) ose ligjore, fillo menjÃ«herÃ« duke i pÃ«rmendur ato si "RREZIQE KRITIKE".

        ### 2. Auditim Ligjor & Faktik
        - **Kontrolli i Afateve:** Krahaso tÃ« gjitha datat nÃ« tekst. A ka data qÃ« bien ndesh me njÃ«ra-tjetrÃ«n? (Psh. NÃ«nshkrimi pas dorÃ«zimit?). NÃ«se po, shÃ«noje me ðŸ”´.
        - **PÃ«rputhshmÃ«ria Ligjore:** Krahaso klauzolat e kontratÃ«s me "BAZA LIGJORE". A mungon ndonjÃ« element i detyrueshÃ«m sipas ligjit (LMD/Civil)? Cito Nenin specifik nÃ«se gjendet nÃ« kontekst.

        ### 3. Analiza e Dokumentit
        Nxirr detajet kryesore:
        - PalÃ«t: ...
        - Objekti: ...
        - Vlera: ...

        ### 4. Rekomandime Strategjike
        Ã‡farÃ« duhet tÃ« pÃ«rmirÃ«sohet ose ndryshohet urgjentisht nÃ« dokument?

        STILI I TÃ‹ MENDUARIT:
        - Mos beso verbÃ«risht tekstin. NÃ«se data e dokumentit Ã«shtÃ« 15 Dhjetor dhe afati Ã«shtÃ« 1 Dhjetor, kjo Ã«shtÃ« e pamundur. IDENTIFIKOJÃ‹ KÃ‹TÃ‹ GABIM.
        - Ji specifik. Mos thuaj "sipas ligjit", thuaj "Sipas Nenit X tÃ« Ligjit Y (nÃ«se Ã«shtÃ« nÃ« kontekst)".
        """

        user_message = f"KONTEKSTI I DOSJES:\n{context_text}\n\nPYETJA/KÃ‹RKESA: {query}"

        try:
            if not self.client:
                raise Exception("Client not initialized")

            stream = await self.client.chat.completions.create(
                model=OPENROUTER_MODEL,
                messages=[
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                temperature=0.1, 
                stream=True,
                extra_headers={ "HTTP-Referer": "https://juristi.tech", "X-Title": "Juristi AI" }
            )

            async for chunk in stream:
                content = chunk.choices[0].delta.content
                if content:
                    yield content
            
        except Exception as e:
            logger.error(f"OpenRouter API Error: {e}")
            yield await self._call_local_backup(system_prompt, user_message)