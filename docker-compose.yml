# FILE: docker-compose.yml
# PHOENIX PROTOCOL - DATA PERSISTENCE FIX
# 1. DIAGNOSIS: The 'chroma' service was not persisting data because its volume was mapped to the wrong internal directory.
# 2. FIX: Corrected the volume mapping for the 'chroma_data' volume to point to the correct internal path: '/chroma/chroma'.
# 3. BEHAVIOR: ChromaDB will now write all its data to the persistent Docker volume, ensuring that the knowledge base survives restarts.

services:
  # -------------------------------------------------------
  # JURISTI AI CORE (Embeddings, NER, Categorization)
  # -------------------------------------------------------
  ai-core-service:
    build: 
      context: ./ai-core-service
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - "8010:8000"
    networks:
      - phoenix_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  # -------------------------------------------------------
  # LOCAL LLM ENGINE (The Free Brain)
  # -------------------------------------------------------
  local-llm:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - phoenix_net

  # -------------------------------------------------------
  # INFRASTRUCTURE & BACKEND
  # -------------------------------------------------------
  caddy:
    image: caddy:latest
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
    networks: [phoenix_net]
    depends_on:
      backend:
        condition: service_healthy

  backend:
    build: { context: ./backend }
    restart: unless-stopped
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --log-level info --proxy-headers
    env_file: ./.env
    volumes:
      - ./backend/data:/app/data
    networks: [phoenix_net]
    depends_on: 
      mongo: { condition: service_healthy }
      redis: { condition: service_healthy }
      ai-core-service: { condition: service_healthy }
      local-llm: { condition: service_started }
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s

  celery:
    build: { context: ./backend }
    restart: unless-stopped
    command: celery -A app.worker.celery_app worker --loglevel=info
    env_file: ./.env
    volumes:
      - ./backend/data:/app/data
    networks: [phoenix_net]
    depends_on: 
      redis: { condition: service_healthy } 
      mongo: { condition: service_healthy }
      backend: { condition: service_started }

  # -------------------------------------------------------
  # DATABASE & CACHE
  # -------------------------------------------------------
  mongo:
    image: mongo:6.0
    restart: unless-stopped
    env_file: ./.env
    networks: [phoenix_net]
    volumes: [mongo_data:/data/db]
    healthcheck: { test: echo 'db.runCommand("ping").ok' | mongosh --quiet, interval: 15s, timeout: 10s, retries: 5 }
    stop_grace_period: 20s

  redis:
    image: redis:7
    restart: unless-stopped
    volumes: [redis_data:/data]
    networks: [phoenix_net]
    healthcheck: { test: ["CMD", "redis-cli", "ping"], interval: 15s, timeout: 10s, retries: 5 }
    stop_grace_period: 20s

  chroma:
    image: chromadb/chroma:latest
    restart: unless-stopped
    ports: ["8002:8000"]
    networks: [phoenix_net]
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma # This tells Chroma WHERE to save inside the container.
    volumes:
      # PHOENIX FIX: This maps the persistent Docker volume to the correct internal path specified above.
      - chroma_data:/chroma/chroma
    depends_on: [backend]

  # --- GRAPH DATABASE (Neo4j) ---
  neo4j:
    image: neo4j:5
    restart: unless-stopped
    ports:
      - "7474:7474" # HTTP Interface (Browser)
      - "7687:7687" # Bolt Protocol (App connection)
    environment:
      - NEO4J_AUTH=neo4j/${NEO4J_PASSWORD:-password}
      - NEO4J_PLUGINS=["apoc"]
      - NEO4J_dbms_security_procedures_unrestricted=apoc.*
    volumes:
      - neo4j_data:/data
      - neo4j_logs:/logs
    networks:
      - phoenix_net
    healthcheck:
      test: ["CMD-SHELL", "wget --no-verbose --tries=1 --spider localhost:7474 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 5

volumes:
  mongo_data: {}
  chroma_data: {}
  redis_data: {}
  caddy_data: {}
  ollama_data: {}
  neo4j_data: {}
  neo4j_logs: {}

networks:
  phoenix_net:
    driver: bridge