# FILE: docker-compose.yml
# PHOENIX PROTOCOL - PHASE 2: HYBRID INTELLIGENCE
# Status: FIXED - Added Volume Mapping for Backend Data Access.

services:
  # -------------------------------------------------------
  # JURISTI AI CORE (Embeddings, NER, Categorization)
  # -------------------------------------------------------
  ai-core-service:
    build: 
      context: ./ai-core-service
      dockerfile: Dockerfile
    restart: unless-stopped
    ports:
      - "8010:8000"
    networks:
      - phoenix_net
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 10s
      timeout: 10s
      retries: 5
      start_period: 30s

  # -------------------------------------------------------
  # LOCAL LLM ENGINE (The Free Brain)
  # -------------------------------------------------------
  local-llm:
    image: ollama/ollama:latest
    restart: unless-stopped
    volumes:
      - ollama_data:/root/.ollama
    networks:
      - phoenix_net
    # No healthcheck needed for Ollama, it's robust.

  # -------------------------------------------------------
  # INFRASTRUCTURE & BACKEND
  # -------------------------------------------------------
  caddy:
    image: caddy:latest
    restart: unless-stopped
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./Caddyfile:/etc/caddy/Caddyfile:ro
      - caddy_data:/data
    networks: [phoenix_net]
    depends_on:
      backend:
        condition: service_healthy

  backend:
    build: { context: ./backend }
    restart: unless-stopped
    command: uvicorn app.main:app --host 0.0.0.0 --port 8000 --log-level info --proxy-headers
    env_file: ./.env
    # PHOENIX FIX: Mount data volume so container sees uploaded laws
    volumes:
      - ./backend/data:/app/data
    networks: [phoenix_net]
    depends_on: 
      mongo: { condition: service_healthy }
      redis: { condition: service_healthy }
      ai-core-service: { condition: service_healthy }
      local-llm: { condition: service_started }
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 15s
      timeout: 10s
      retries: 5
      start_period: 30s

  celery:
    build: { context: ./backend }
    restart: unless-stopped
    command: celery -A app.worker.celery_app worker --loglevel=info
    env_file: ./.env
    # Worker also needs access to data for processing
    volumes:
      - ./backend/data:/app/data
    networks: [phoenix_net]
    depends_on: { redis: { condition: service_healthy }, mongo: { condition: service_healthy }, backend: { condition: service_started } }

  # -------------------------------------------------------
  # DATABASE & CACHE
  # -------------------------------------------------------
  mongo:
    image: mongo:6.0
    restart: unless-stopped
    env_file: ./.env
    networks: [phoenix_net]
    volumes: [mongo_data:/data/db]
    healthcheck: { test: echo 'db.runCommand("ping").ok' | mongosh --quiet, interval: 15s, timeout: 10s, retries: 5 }
    stop_grace_period: 20s

  redis:
    image: redis:7
    restart: unless-stopped
    volumes: [redis_data:/data]
    networks: [phoenix_net]
    healthcheck: { test: ["CMD", "redis-cli", "ping"], interval: 15s, timeout: 10s, retries: 5 }
    stop_grace_period: 20s

  chroma:
    image: chromadb/chroma:latest
    restart: unless-stopped
    ports: ["8002:8000"]
    networks: [phoenix_net]
    volumes: [chroma_data:/data/db]
    depends_on: [backend]

volumes:
  mongo_data: {}
  chroma_data: {}
  redis_data: {}
  caddy_data: {}
  ollama_data: {}

networks:
  phoenix_net:
    driver: bridge